{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfb0d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 2018310064 λ¬Έν•™μ¤€\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98730235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "num_epoch = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06df80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3fad779",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "919a2d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "download_path = './CIFAR'\n",
    "dataset = dset.CIFAR10(download_path, transform=transform_train, train = True, download = True)\n",
    "test_dataset = dset.CIFAR10(download_path, transform=transform_test, train = False, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082dac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, [40000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1d101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c5c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning : resnet50\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(weights=\"IMAGENET1K_V2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a754ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_funcion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378e843e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, train_loss : 0.8608, val_loss : 0.6532, val_acc : 78.97 %, lr : 0.001000, elapsed time : 27.04 sec\n",
      "epoch : 2, train_loss : 0.7138, val_loss : 0.4762, val_acc : 84.20 %, lr : 0.000998, elapsed time : 78.02 sec\n",
      "epoch : 4, train_loss : 0.4998, val_loss : 0.4478, val_acc : 86.20 %, lr : 0.000994, elapsed time : 128.96 sec\n",
      "epoch : 6, train_loss : 0.2029, val_loss : 0.4517, val_acc : 85.79 %, lr : 0.000988, elapsed time : 179.60 sec\n",
      "epoch : 8, train_loss : 0.3949, val_loss : 0.4872, val_acc : 85.36 %, lr : 0.000980, elapsed time : 230.29 sec\n",
      "epoch : 10, train_loss : 0.2665, val_loss : 0.4590, val_acc : 85.99 %, lr : 0.000970, elapsed time : 281.08 sec\n",
      "epoch : 12, train_loss : 0.8856, val_loss : 0.4913, val_acc : 85.72 %, lr : 0.000959, elapsed time : 331.78 sec\n",
      "epoch : 14, train_loss : 0.9420, val_loss : 0.5013, val_acc : 85.66 %, lr : 0.000946, elapsed time : 382.32 sec\n",
      "epoch : 16, train_loss : 0.3197, val_loss : 0.4814, val_acc : 86.09 %, lr : 0.000930, elapsed time : 432.77 sec\n",
      "epoch : 18, train_loss : 0.8544, val_loss : 0.5051, val_acc : 85.45 %, lr : 0.000914, elapsed time : 483.60 sec\n",
      "epoch : 20, train_loss : 0.6075, val_loss : 0.4750, val_acc : 85.59 %, lr : 0.000895, elapsed time : 534.20 sec\n",
      "epoch : 22, train_loss : 1.0664, val_loss : 0.4975, val_acc : 85.74 %, lr : 0.000875, elapsed time : 584.78 sec\n",
      "epoch : 24, train_loss : 0.7461, val_loss : 0.5090, val_acc : 85.83 %, lr : 0.000854, elapsed time : 635.33 sec\n",
      "epoch : 26, train_loss : 0.2866, val_loss : 0.4912, val_acc : 85.76 %, lr : 0.000831, elapsed time : 685.99 sec\n",
      "epoch : 28, train_loss : 0.6185, val_loss : 0.5107, val_acc : 85.42 %, lr : 0.000807, elapsed time : 736.49 sec\n",
      "epoch : 30, train_loss : 0.7332, val_loss : 0.5270, val_acc : 85.68 %, lr : 0.000781, elapsed time : 786.88 sec\n",
      "epoch : 32, train_loss : 0.2091, val_loss : 0.5241, val_acc : 85.27 %, lr : 0.000755, elapsed time : 837.42 sec\n",
      "epoch : 34, train_loss : 0.4250, val_loss : 0.5055, val_acc : 85.84 %, lr : 0.000727, elapsed time : 887.77 sec\n",
      "epoch : 36, train_loss : 0.4869, val_loss : 0.5153, val_acc : 86.30 %, lr : 0.000699, elapsed time : 938.16 sec\n",
      "epoch : 38, train_loss : 0.6212, val_loss : 0.5179, val_acc : 86.04 %, lr : 0.000670, elapsed time : 988.55 sec\n",
      "epoch : 40, train_loss : 0.6774, val_loss : 0.5061, val_acc : 86.95 %, lr : 0.000640, elapsed time : 1039.43 sec\n",
      "epoch : 42, train_loss : 0.5283, val_loss : 0.5546, val_acc : 86.05 %, lr : 0.000609, elapsed time : 1090.11 sec\n",
      "epoch : 44, train_loss : 0.4606, val_loss : 0.5462, val_acc : 86.38 %, lr : 0.000579, elapsed time : 1140.77 sec\n",
      "epoch : 46, train_loss : 0.4777, val_loss : 0.5196, val_acc : 86.98 %, lr : 0.000548, elapsed time : 1191.80 sec\n",
      "epoch : 48, train_loss : 0.4459, val_loss : 0.5491, val_acc : 86.41 %, lr : 0.000516, elapsed time : 1242.36 sec\n",
      "epoch : 50, train_loss : 0.9533, val_loss : 0.5608, val_acc : 86.02 %, lr : 0.000485, elapsed time : 1292.98 sec\n",
      "epoch : 52, train_loss : 0.9934, val_loss : 0.5623, val_acc : 86.75 %, lr : 0.000453, elapsed time : 1343.79 sec\n",
      "epoch : 54, train_loss : 0.5084, val_loss : 0.5564, val_acc : 86.88 %, lr : 0.000422, elapsed time : 1394.30 sec\n",
      "epoch : 56, train_loss : 0.5307, val_loss : 0.5579, val_acc : 87.17 %, lr : 0.000392, elapsed time : 1444.79 sec\n",
      "epoch : 58, train_loss : 1.1111, val_loss : 0.5920, val_acc : 87.04 %, lr : 0.000361, elapsed time : 1495.03 sec\n",
      "epoch : 60, train_loss : 0.7536, val_loss : 0.5902, val_acc : 86.99 %, lr : 0.000331, elapsed time : 1545.49 sec\n",
      "epoch : 62, train_loss : 0.8393, val_loss : 0.6033, val_acc : 87.15 %, lr : 0.000302, elapsed time : 1595.87 sec\n",
      "epoch : 64, train_loss : 0.3892, val_loss : 0.5704, val_acc : 87.52 %, lr : 0.000274, elapsed time : 1646.21 sec\n",
      "epoch : 66, train_loss : 0.4602, val_loss : 0.6115, val_acc : 87.16 %, lr : 0.000246, elapsed time : 1696.56 sec\n",
      "epoch : 68, train_loss : 0.5363, val_loss : 0.6010, val_acc : 87.80 %, lr : 0.000220, elapsed time : 1746.96 sec\n",
      "epoch : 70, train_loss : 0.8018, val_loss : 0.6149, val_acc : 87.87 %, lr : 0.000194, elapsed time : 1797.58 sec\n",
      "epoch : 72, train_loss : 0.5728, val_loss : 0.6231, val_acc : 87.83 %, lr : 0.000170, elapsed time : 1848.17 sec\n",
      "epoch : 74, train_loss : 0.3684, val_loss : 0.6182, val_acc : 87.98 %, lr : 0.000147, elapsed time : 1898.28 sec\n",
      "epoch : 76, train_loss : 0.2424, val_loss : 0.6380, val_acc : 88.29 %, lr : 0.000126, elapsed time : 1948.75 sec\n",
      "epoch : 78, train_loss : 0.6196, val_loss : 0.6632, val_acc : 88.03 %, lr : 0.000106, elapsed time : 1999.20 sec\n",
      "epoch : 80, train_loss : 0.6825, val_loss : 0.6580, val_acc : 87.96 %, lr : 0.000087, elapsed time : 2049.62 sec\n",
      "epoch : 82, train_loss : 0.3406, val_loss : 0.6378, val_acc : 88.55 %, lr : 0.000071, elapsed time : 2100.07 sec\n",
      "epoch : 84, train_loss : 0.8121, val_loss : 0.6747, val_acc : 88.43 %, lr : 0.000055, elapsed time : 2150.36 sec\n",
      "epoch : 86, train_loss : 0.1724, val_loss : 0.6556, val_acc : 88.42 %, lr : 0.000042, elapsed time : 2200.61 sec\n",
      "epoch : 88, train_loss : 0.2240, val_loss : 0.6629, val_acc : 88.44 %, lr : 0.000031, elapsed time : 2251.08 sec\n",
      "epoch : 90, train_loss : 0.1162, val_loss : 0.6760, val_acc : 88.16 %, lr : 0.000021, elapsed time : 2302.52 sec\n",
      "epoch : 92, train_loss : 0.1340, val_loss : 0.6672, val_acc : 88.56 %, lr : 0.000013, elapsed time : 2353.27 sec\n",
      "epoch : 94, train_loss : 0.5776, val_loss : 0.6949, val_acc : 88.18 %, lr : 0.000007, elapsed time : 2403.83 sec\n",
      "epoch : 96, train_loss : 0.6595, val_loss : 0.6863, val_acc : 88.42 %, lr : 0.000003, elapsed time : 2454.35 sec\n",
      "epoch : 98, train_loss : 0.6752, val_loss : 0.6924, val_acc : 88.20 %, lr : 0.000001, elapsed time : 2505.10 sec\n",
      "epoch : 100, train_loss : 0.1283, val_loss : 0.6674, val_acc : 88.52 %, lr : 0.000001, elapsed time : 2555.84 sec\n",
      "epoch : 102, train_loss : 0.6793, val_loss : 0.6916, val_acc : 88.41 %, lr : 0.000003, elapsed time : 2606.25 sec\n",
      "epoch : 104, train_loss : 0.5804, val_loss : 0.6759, val_acc : 88.21 %, lr : 0.000007, elapsed time : 2656.71 sec\n",
      "epoch : 106, train_loss : 0.0553, val_loss : 0.6690, val_acc : 88.53 %, lr : 0.000013, elapsed time : 2706.97 sec\n",
      "epoch : 108, train_loss : 0.1307, val_loss : 0.6668, val_acc : 88.38 %, lr : 0.000021, elapsed time : 2757.03 sec\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "start_time = time.time()\n",
    "\n",
    "len_val_loader = len(val_loader)\n",
    "len_val_dataset = len(val_dataset)\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    val_num_corrects = 0.0\n",
    "    \n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        x = image.to(device)\n",
    "        y_ = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_funcion(output, y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            loss = loss_funcion(val_outputs, val_labels)\n",
    "\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_num_corrects += torch.sum(val_preds == val_labels.data)\n",
    "            \n",
    "        \n",
    "    train_loss = loss.cpu().detach().numpy()\n",
    "    \n",
    "    val_epoch_loss = val_loss / len_val_loader\n",
    "    val_epoch_acc = 100 * val_num_corrects.float() / len_val_dataset\n",
    "    \n",
    "    if (i % 2 == 0):\n",
    "        print(f\"epoch : {i}, train_loss : {train_loss:.4f}, val_loss : {val_epoch_loss:.4f}, val_acc : {val_epoch_acc:.2f} %, lr : {optimizer.param_groups[0]['lr']:.6f}, elapsed time : {time.time() - start_time:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a62fedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : {} 87.7699966430664\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "        x = image.to(device)\n",
    "        y_ = label.to(device)\n",
    "\n",
    "        output = model.forward(x)\n",
    "        _,output_index = torch.max(output,1)\n",
    "        total += label.size(0)\n",
    "        correct += (output_index == y_).sum().float()\n",
    "\n",
    "    print(\"Accuracy : {}\", format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df3ee86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './CIFAR/model_resnet50.pt'\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25dcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
